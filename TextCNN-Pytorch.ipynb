{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of train: 65328, dev:872, test:2021\n",
      "train.fields: {'text': <torchtext.data.field.Field object at 0x000001E605905250>, 'label': <torchtext.data.field.Field object at 0x000001E6054D2310>} torch.Size([14795, 100])\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "import time\n",
    "\n",
    "TEXT = data.Field(lower=True, fix_length=60, batch_first=True)\n",
    "LABEL = data.Field(sequential=False,)\n",
    "\n",
    "#sst = datasets.SST.splits(TEXT, LABEL, fine_grained=True)\n",
    "#train, dev, test = sst[0], sst[1], sst[2]\n",
    "train, dev, test = data.TabularDataset.splits(\n",
    "    path='SST-2', train='train.tsv', validation='dev.tsv',\n",
    "    test='test.tsv', format='tsv', skip_header=True,\n",
    "    fields=[('text', TEXT), ('label', LABEL)])\n",
    "print(\"the size of train: {}, dev:{}, test:{}\".format(len(train.examples), len(dev.examples), len(test.examples)))\n",
    "\n",
    "TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=100), max_size=25000)\n",
    "LABEL.build_vocab(train,)\n",
    "\n",
    "print(\"train.fields:\", train.fields, TEXT.vocab.vectors.shape)\n",
    "\n",
    "train_iter, dev_iter, test_iter = data.BucketIterator.splits(\n",
    "        (train, dev, test), batch_sizes=(512, 64, 64), sort_key=lambda x: len(x.text), sort_within_batch=True, repeat=False\n",
    "    )\n",
    "train_iter.repeat = False\n",
    "test_iter.repeat = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text-CNN Parameter\n",
    "sequence_length = 60\n",
    "#batch_size = 32\n",
    "vocab_size = TEXT.vocab.vectors.shape[0]\n",
    "embedding_size = TEXT.vocab.vectors.shape[1]\n",
    "num_classes = 5  # 0 or 1\n",
    "filter_sizes = [2, 3, 5, 2, 3, 5] # n-gram window\n",
    "num_filters = 6\n",
    "lr = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Square(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Square, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.pow(x, 2)\n",
    "        return x\n",
    "\n",
    "class Sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Sigmoid, self).__init__()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = 0.5 + 0.197*x - 0.004*torch.pow(x, 3)\n",
    "        return x\n",
    "    \n",
    "class Softmax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Softmax, self).__init__()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = 0.25 + 0.5*x - 0.125*torch.pow(x, 2)\n",
    "        return x\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Swish, self).__init__()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = 0.1198 + 0.5*x + 0.1473*torch.pow(x, 2) - -0.002012*torch.pow(x, 4)\n",
    "        return x\n",
    "    \n",
    "class HETextCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HETextCNN, self).__init__()\n",
    "\n",
    "        self.num_filters_total = num_filters * len(filter_sizes)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(1, num_filters, (kernel, embedding_size), bias=False),\n",
    "                Swish(),\n",
    "                nn.AvgPool2d((sequence_length - kernel + 1,1))\n",
    "            ) for kernel in filter_sizes])\n",
    "        \n",
    "        self.fc = nn.Linear(self.num_filters_total,num_classes)\n",
    "        self.sm = Softmax()\n",
    "                           \n",
    "    def forward(self, X):\n",
    "        embedded_chars = self.embedding(X)# [batch_size, sequence_length, sequence_length]\n",
    "        embedded_chars = embedded_chars.unsqueeze(1)\n",
    "\n",
    "        out = [conv(embedded_chars) for conv in self.convs]\n",
    "        out = torch.cat(out, dim=1)\n",
    "        out = out.view(embedded_chars.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        logit = self.sm(out)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(preds, y):\n",
    "    correct = torch.eq(preds, y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "train_set_size = 128\n",
    "\n",
    "def train(model, optimizer, criterion):\n",
    "    avg_acc = []\n",
    "    avg_loss = []\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx , batch in enumerate(train_iter):\n",
    "        if batch_idx >= train_set_size:\n",
    "            continue\n",
    "        text, labels = batch.text , batch.label - 1\n",
    "\n",
    "        predicted = model(text)\n",
    "\n",
    "        acc = binary_acc(torch.max(predicted, dim=1)[1], labels)\n",
    "        avg_acc.append(acc)\n",
    "        loss = criterion(predicted, labels)\n",
    "        avg_loss.append(loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return np.array(avg_acc).mean()\n",
    "\n",
    "def evaluate(model, criterion):\n",
    "    avg_acc = []\n",
    "    model.eval()\n",
    "    for batch_idx , batch in enumerate(dev_iter):\n",
    "        text, labels = batch.text , batch.label - 1\n",
    "        predicted = model(text)\n",
    "\n",
    "        acc = binary_acc(torch.max(predicted, dim=1)[1], labels)\n",
    "        avg_acc.append(acc)\n",
    "\n",
    "    return np.array(avg_acc).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HETextCNN(\n",
      "  (embedding): Embedding(14795, 100)\n",
      "  (convs): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 6, kernel_size=(2, 100), stride=(1, 1), bias=False)\n",
      "      (1): Swish()\n",
      "      (2): AvgPool2d(kernel_size=(59, 1), stride=(59, 1), padding=0)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(1, 6, kernel_size=(3, 100), stride=(1, 1), bias=False)\n",
      "      (1): Swish()\n",
      "      (2): AvgPool2d(kernel_size=(58, 1), stride=(58, 1), padding=0)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(1, 6, kernel_size=(5, 100), stride=(1, 1), bias=False)\n",
      "      (1): Swish()\n",
      "      (2): AvgPool2d(kernel_size=(56, 1), stride=(56, 1), padding=0)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(1, 6, kernel_size=(2, 100), stride=(1, 1), bias=False)\n",
      "      (1): Swish()\n",
      "      (2): AvgPool2d(kernel_size=(59, 1), stride=(59, 1), padding=0)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(1, 6, kernel_size=(3, 100), stride=(1, 1), bias=False)\n",
      "      (1): Swish()\n",
      "      (2): AvgPool2d(kernel_size=(58, 1), stride=(58, 1), padding=0)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Conv2d(1, 6, kernel_size=(5, 100), stride=(1, 1), bias=False)\n",
      "      (1): Swish()\n",
      "      (2): AvgPool2d(kernel_size=(56, 1), stride=(56, 1), padding=0)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=36, out_features=5, bias=True)\n",
      "  (sm): Softmax()\n",
      ")\n",
      "epoch=0,训练准确率=0.02734375\n",
      "epoch=0,测试准确率=0.5149553418159485\n",
      "epoch=1,训练准确率=0.509765625\n",
      "epoch=1,测试准确率=0.5082589387893677\n",
      "epoch=2,训练准确率=0.5625\n",
      "epoch=2,测试准确率=0.5082589387893677\n",
      "epoch=3,训练准确率=0.5703125\n",
      "epoch=3,测试准确率=0.5011160969734192\n",
      "epoch=4,训练准确率=0.580078125\n",
      "epoch=4,测试准确率=0.4772321581840515\n",
      "epoch=5,训练准确率=0.5\n",
      "epoch=5,测试准确率=0.4716517925262451\n",
      "epoch=6,训练准确率=0.56640625\n",
      "epoch=6,测试准确率=0.4794642925262451\n",
      "epoch=7,训练准确率=0.447265625\n",
      "epoch=7,测试准确率=0.4783482253551483\n",
      "epoch=8,训练准确率=0.474609375\n",
      "epoch=8,测试准确率=0.5149553418159485\n",
      "epoch=9,训练准确率=0.623046875\n",
      "epoch=9,测试准确率=0.5093749761581421\n",
      "epoch=10,训练准确率=0.59765625\n",
      "epoch=10,测试准确率=0.5082589387893677\n",
      "epoch=11,训练准确率=0.58203125\n",
      "epoch=11,测试准确率=0.5082589387893677\n",
      "epoch=12,训练准确率=0.57421875\n",
      "epoch=12,测试准确率=0.5082589387893677\n",
      "epoch=13,训练准确率=0.486328125\n",
      "epoch=13,测试准确率=0.5082589387893677\n",
      "epoch=14,训练准确率=0.521484375\n",
      "epoch=14,测试准确率=0.5082589387893677\n",
      "epoch=15,训练准确率=0.56640625\n",
      "epoch=15,测试准确率=0.5283482074737549\n",
      "epoch=16,训练准确率=0.39453125\n",
      "epoch=16,测试准确率=0.4881696403026581\n",
      "epoch=17,训练准确率=0.46875\n",
      "epoch=17,测试准确率=0.4917410910129547\n",
      "epoch=18,训练准确率=0.5\n",
      "epoch=18,测试准确率=0.4917410910129547\n",
      "epoch=19,训练准确率=0.447265625\n",
      "epoch=19,测试准确率=0.4917410910129547\n",
      "epoch=20,训练准确率=0.470703125\n",
      "epoch=20,测试准确率=0.4917410910129547\n",
      "epoch=21,训练准确率=0.39453125\n",
      "epoch=21,测试准确率=0.4917410910129547\n",
      "epoch=22,训练准确率=0.490234375\n",
      "epoch=22,测试准确率=0.4917410910129547\n",
      "epoch=23,训练准确率=0.48828125\n",
      "epoch=23,测试准确率=0.4928571581840515\n",
      "epoch=24,训练准确率=0.51953125\n",
      "epoch=24,测试准确率=0.4794642925262451\n",
      "epoch=25,训练准确率=0.51171875\n",
      "epoch=25,测试准确率=0.4984374940395355\n",
      "epoch=26,训练准确率=0.62109375\n",
      "epoch=26,测试准确率=0.5082589387893677\n",
      "epoch=27,训练准确率=0.482421875\n",
      "epoch=27,测试准确率=0.5082589387893677\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8d678c59217f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch={},训练准确率={}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-3e3bcda0be98>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, criterion)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#if batch_idx >= train_set_size:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\syft\\lib\\site-packages\\torchtext\\data\\iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    154\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\syft\\lib\\site-packages\\torchtext\\data\\batch.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, dataset, device)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                     \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\syft\\lib\\site-packages\\torchtext\\data\\field.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, batch, device)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m    236\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\syft\\lib\\site-packages\\torchtext\\data\\field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[1;34m(self, arr, device)\u001b[0m\n\u001b[0;32m    357\u001b[0m                 \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpostprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m         \u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = HETextCNN()\n",
    "print(model)\n",
    "\n",
    "pretrained_embedding = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embedding)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_accs, test_accs = [], []\n",
    "\n",
    "for epoch in range(150):\n",
    "\n",
    "    train_acc = train(model, optimizer, criterion)\n",
    "    print('epoch={},训练准确率={}'.format(epoch, train_acc))\n",
    "    test_acc = evaluate(model, criterion)\n",
    "    print(\"epoch={},测试准确率={}\".format(epoch, test_acc))\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

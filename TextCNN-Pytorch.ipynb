{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.fields: {'text': <torchtext.data.field.Field object at 0x000001E919195970>, 'label': <torchtext.data.field.Field object at 0x000001E918E45E50>} torch.Size([16583, 50])\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "TEXT = data.Field(lower=True, fix_length=50, batch_first=True)\n",
    "LABEL = data.Field(sequential=False,)\n",
    "\n",
    "sst = datasets.SST.splits(TEXT, LABEL, fine_grained=True)\n",
    "train, dev, test = sst[0], sst[1], sst[2]\n",
    "#train, dev, test = data.TabularDataset.splits(\n",
    "#    path='SST-2', train='train.tsv', validation='dev.tsv',\n",
    "#    test='test.tsv', format='tsv', skip_header=True,\n",
    "#    fields=[('text', TEXT), ('label', LABEL)])\n",
    "#print(\"the size of train: {}, dev:{}, test:{}\".format(len(train.examples), len(dev.examples), len(test.examples)))\n",
    "\n",
    "TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=50), max_size=25000)\n",
    "LABEL.build_vocab(train,)\n",
    "\n",
    "print(\"train.fields:\", train.fields, TEXT.vocab.vectors.shape)\n",
    "\n",
    "train_iter, dev_iter, test_iter = data.BucketIterator.splits(\n",
    "        (train, dev, test), batch_sizes=(64, 64, 64), sort_key=lambda x: len(x.text), sort_within_batch=True, repeat=False\n",
    "    )\n",
    "train_iter.repeat = False\n",
    "test_iter.repeat = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text-CNN Parameter\n",
    "sequence_length = 50\n",
    "#batch_size = 32\n",
    "vocab_size = TEXT.vocab.vectors.shape[0]\n",
    "embedding_size = TEXT.vocab.vectors.shape[1]\n",
    "num_classes = 5  # 0 or 1\n",
    "filter_sizes = [2, 3, 5, 2, 3, 5] # n-gram window\n",
    "num_filters = 6\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Square(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Square, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.pow(x, 2)\n",
    "        return x\n",
    "\n",
    "class Sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Sigmoid, self).__init__()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = 0.5 + 0.197*x - 0.004*torch.pow(x, 3)\n",
    "        return x\n",
    "    \n",
    "class Softmax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Softmax, self).__init__()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = 0.25 + 0.5*x - 0.125*torch.pow(x, 2)\n",
    "        return x\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Swish, self).__init__()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = 0.1198 + 0.5*x + 0.1473*torch.pow(x, 2) - 0.002012*torch.pow(x, 4)\n",
    "        return x\n",
    "    \n",
    "class HETextCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HETextCNN, self).__init__()\n",
    "\n",
    "        self.num_filters_total = num_filters * len(filter_sizes)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(1, num_filters, (kernel, embedding_size), bias=False),\n",
    "                Swish(),\n",
    "                nn.AvgPool2d((sequence_length - kernel + 1,1))\n",
    "            ) for kernel in filter_sizes])\n",
    "        \n",
    "        self.fc = nn.Linear(self.num_filters_total,num_classes)\n",
    "        self.sm = Softmax()\n",
    "                           \n",
    "    def forward(self, X):\n",
    "        embedded_chars = self.embedding(X)# [batch_size, sequence_length, sequence_length]\n",
    "        embedded_chars = embedded_chars.unsqueeze(1)\n",
    "\n",
    "        out = [conv(embedded_chars) for conv in self.convs]\n",
    "        out = torch.cat(out, dim=1)\n",
    "        out = out.view(embedded_chars.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        logit = self.sm(out)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(preds, y):\n",
    "    correct = torch.eq(preds, y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "train_set_size = 128\n",
    "\n",
    "def train(model, optimizer, criterion):\n",
    "    avg_acc = []\n",
    "    avg_loss = []\n",
    "    model.train()\n",
    "    for batch_idx , batch in enumerate(train_iter):\n",
    "        if batch_idx >= train_set_size:\n",
    "            continue\n",
    "        text, labels = batch.text , batch.label - 1\n",
    "        predicted = model(text)\n",
    "\n",
    "        acc = binary_acc(torch.max(predicted, dim=1)[1], labels)\n",
    "        avg_acc.append(acc)\n",
    "        loss = criterion(predicted, labels)\n",
    "        avg_loss.append(loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return np.array(avg_acc).mean()\n",
    "\n",
    "def evaluate(model, criterion):\n",
    "    avg_acc = []\n",
    "    model.eval()\n",
    "    for batch_idx , batch in enumerate(dev_iter):\n",
    "        text, labels = batch.text , batch.label - 1\n",
    "        predicted = model(text)\n",
    "\n",
    "        acc = binary_acc(torch.max(predicted, dim=1)[1], labels)\n",
    "        avg_acc.append(acc)\n",
    "\n",
    "    return np.array(avg_acc).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HETextCNN(\n",
      "  (embedding): Embedding(16583, 50)\n",
      "  (convs): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 6, kernel_size=(2, 50), stride=(1, 1), bias=False)\n",
      "      (1): Swish()\n",
      "      (2): AvgPool2d(kernel_size=(49, 1), stride=(49, 1), padding=0)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(1, 6, kernel_size=(3, 50), stride=(1, 1), bias=False)\n",
      "      (1): Swish()\n",
      "      (2): AvgPool2d(kernel_size=(48, 1), stride=(48, 1), padding=0)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(1, 6, kernel_size=(5, 50), stride=(1, 1), bias=False)\n",
      "      (1): Swish()\n",
      "      (2): AvgPool2d(kernel_size=(46, 1), stride=(46, 1), padding=0)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(1, 6, kernel_size=(2, 50), stride=(1, 1), bias=False)\n",
      "      (1): Swish()\n",
      "      (2): AvgPool2d(kernel_size=(49, 1), stride=(49, 1), padding=0)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(1, 6, kernel_size=(3, 50), stride=(1, 1), bias=False)\n",
      "      (1): Swish()\n",
      "      (2): AvgPool2d(kernel_size=(48, 1), stride=(48, 1), padding=0)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Conv2d(1, 6, kernel_size=(5, 50), stride=(1, 1), bias=False)\n",
      "      (1): Swish()\n",
      "      (2): AvgPool2d(kernel_size=(46, 1), stride=(46, 1), padding=0)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=36, out_features=5, bias=True)\n",
      "  (sm): Softmax()\n",
      ")\n",
      "epoch=0,训练准确率=0.275390625\n",
      "epoch=0,测试准确率=0.2567441165447235\n",
      "epoch=1,训练准确率=0.310302734375\n",
      "epoch=1,测试准确率=0.3270566165447235\n",
      "epoch=2,训练准确率=0.3717041015625\n",
      "epoch=2,测试准确率=0.3591079115867615\n",
      "epoch=3,训练准确率=0.41796875\n",
      "epoch=3,测试准确率=0.3954326808452606\n",
      "epoch=4,训练准确率=0.466064453125\n",
      "epoch=4,测试准确率=0.40418002009391785\n",
      "epoch=5,训练准确率=0.501708984375\n",
      "epoch=5,测试准确率=0.37987446784973145\n",
      "epoch=6,训练准确率=0.5574951171875\n",
      "epoch=6,测试准确率=0.3990384638309479\n",
      "epoch=7,训练准确率=0.5968017578125\n",
      "epoch=7,测试准确率=0.40331196784973145\n",
      "epoch=8,训练准确率=0.6553955078125\n",
      "epoch=8,测试准确率=0.40418002009391785\n",
      "epoch=9,训练准确率=0.698486328125\n",
      "epoch=9,测试准确率=0.3981704115867615\n",
      "epoch=10,训练准确率=0.73193359375\n",
      "epoch=10,测试准确率=0.4059829115867615\n",
      "epoch=11,训练准确率=0.7806396484375\n",
      "epoch=11,测试准确率=0.40337875485420227\n",
      "epoch=12,训练准确率=0.8017578125\n",
      "epoch=12,测试准确率=0.36271369457244873\n",
      "epoch=13,训练准确率=0.8409423828125\n",
      "epoch=13,测试准确率=0.37733709812164307\n",
      "epoch=14,训练准确率=0.86669921875\n",
      "epoch=14,测试准确率=0.39643430709838867\n",
      "epoch=15,训练准确率=0.8663330078125\n",
      "epoch=15,测试准确率=0.37820515036582947\n",
      "epoch=16,训练准确率=0.89013671875\n",
      "epoch=16,测试准确率=0.3842815160751343\n",
      "epoch=17,训练准确率=0.9053955078125\n",
      "epoch=17,测试准确率=0.3920940160751343\n",
      "epoch=18,训练准确率=0.9305419921875\n",
      "epoch=18,测试准确率=0.36344820261001587\n",
      "epoch=19,训练准确率=0.939453125\n",
      "epoch=19,测试准确率=0.3756009638309479\n",
      "epoch=20,训练准确率=0.93994140625\n",
      "epoch=20,测试准确率=0.37126070261001587\n",
      "epoch=21,训练准确率=0.9453125\n",
      "epoch=21,测试准确率=0.39556625485420227\n"
     ]
    }
   ],
   "source": [
    "model = HETextCNN()\n",
    "print(model)\n",
    "\n",
    "pretrained_embedding = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embedding)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_accs, test_accs = [], []\n",
    "\n",
    "for epoch in range(150):\n",
    "\n",
    "    train_acc = train(model, optimizer, criterion)\n",
    "    print('epoch={},训练准确率={}'.format(epoch, train_acc))\n",
    "    test_acc = evaluate(model, criterion)\n",
    "    print(\"epoch={},测试准确率={}\".format(epoch, test_acc))\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
